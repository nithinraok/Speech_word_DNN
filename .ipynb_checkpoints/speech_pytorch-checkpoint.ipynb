{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import  transforms,datasets\n",
    "from torch.utils import data\n",
    "import librosa\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bed': 0, 'bird': 1, 'cat': 2, 'dog': 3, 'down': 4, 'eight': 5, 'five': 6, 'four': 7, 'go': 8, 'happy': 9, 'house': 10, 'left': 11, 'marvin': 12, 'nine': 13, 'no': 14, 'off': 15, 'on': 16, 'one': 17, 'right': 18, 'seven': 19, 'sheila': 20, 'six': 21, 'stop': 22, 'three': 23, 'tree': 24, 'two': 25, 'up': 26, 'wow': 27, 'yes': 28, 'zero': 29}\n"
     ]
    }
   ],
   "source": [
    "categories = !ls Data/speech_commands/train | sort -u \n",
    "categories=categories[1:]\n",
    "category_dict={cat:i for i,cat in enumerate(categories)}\n",
    "print(category_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition={}\n",
    "df=pd.read_csv('Data/speech_commands/csvs/train.csv')\n",
    "partition['train']=df['file_name'].get_values()\n",
    "partition['train_labels']=df['label'].get_values()\n",
    "\n",
    "df=pd.read_csv('Data/speech_commands/csvs/valid.csv')\n",
    "partition['validation']=df['file_name'].get_values()\n",
    "partition['validation_labels']=df['label'].get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self,filenames,labels):\n",
    "        self.filenames=filenames\n",
    "        self.labels=labels\n",
    "        self.sr=16000\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        file = self.filenames[index]\n",
    "        wav,_ = librosa.load(file,self.sr)\n",
    "        wav = librosa.util.normalize(wav)\n",
    "        wav = librosa.util.pad_center(wav,self.sr)\n",
    "        mfcc_feat= librosa.feature.mfcc(wav,self.sr,n_mfcc=13)\n",
    "        delta_feat = mfcc_feat[:-1]-mfcc_feat[1:]\n",
    "#         mfcc_delta = librosa.feature.delta(mfcc,order=2)\n",
    "        deltadelta_feat = delta_feat[:-1]-delta_feat[1:]\n",
    "        #Removing the first two frames\n",
    "        mfcc_feat = mfcc_feat[2:]\n",
    "        delta_feat = delta_feat[1:]\n",
    "\n",
    "        full_input = np.concatenate((mfcc_feat,delta_feat,deltadelta_feat), axis=0)\n",
    "\n",
    "        mfcc = torch.from_numpy(full_input).float().unsqueeze(0)\n",
    "        \n",
    "        y = self.labels[index]\n",
    "        return mfcc,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=AudioDataset(partition['train'],partition['train_labels'])\n",
    "valid_dataset=AudioDataset(partition['validation'],partition['validation_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
    "valid_loader = data.DataLoader(valid_dataset,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=iter(train_loader)\n",
    "x,y=next(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 33, 32])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input=33*32\n",
    "n_hidden=[512,256,64]\n",
    "n_output=30\n",
    "\n",
    "Model = nn.Sequential(nn.Linear(n_input,n_hidden[0]),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(p=0.2), \n",
    "                     nn.Linear(n_hidden[0],n_hidden[1]),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(p=0.2),\n",
    "                     nn.Linear(n_hidden[1],n_hidden[2]),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(p=0.2),\n",
    "                     nn.Linear(n_hidden[2],n_output),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(Model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=1056, out_features=512, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.2)\n",
      "  (3): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Dropout(p=0.2)\n",
      "  (6): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (7): ReLU()\n",
      "  (8): Dropout(p=0.2)\n",
      "  (9): Linear(in_features=64, out_features=30, bias=True)\n",
      "  (10): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(Model,trainloader,testloader,criterion,optimizer,epochs):\n",
    "    test_losses,train_losses=[],[]\n",
    "    for e in range(epochs):\n",
    "        running_loss=0;\n",
    "\n",
    "        Model.train();\n",
    "        for images,labels in trainloader:\n",
    "            images_t = images.view(images.shape[0],-1);\n",
    "            optimizer.zero_grad();\n",
    "\n",
    "            logits=Model.forward(images_t);\n",
    "            loss_t=criterion(logits,labels);\n",
    "            loss_t.backward();\n",
    "            optimizer.step();\n",
    "\n",
    "            running_loss+=loss_t;\n",
    "\n",
    "        else:\n",
    "            test_loss,accuracy=validation(Model,testloader,criterion);\n",
    "\n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                      \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "                      \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "                      \"Test Accuracy: {:.3f}\".format(accuracy))\n",
    "\n",
    "        test_losses.append(test_loss/len(testloader))\n",
    "        train_losses.append(running_loss/len(trainloader))\n",
    "\n",
    "    return train_losses,test_losses,accuracy\n",
    "\n",
    "def validation(Model,testloader,criterion):\n",
    "    test_loss=0;\n",
    "    accuracy=0;\n",
    "\n",
    "    Model.eval();\n",
    "    images_num=0;\n",
    "    with torch.no_grad():\n",
    "        for images,labels in testloader:\n",
    "            images_num+=images.shape[0];\n",
    "            images_t=images.view(images.shape[0],-1);\n",
    "            logits=Model.forward(images_t);\n",
    "            loss_t=criterion(logits,labels)\n",
    "            test_loss+=loss_t;\n",
    "\n",
    "            _,pred_labels=torch.topk(logits,1,dim=1)\n",
    "            equality=(labels==pred_labels.view(*labels.shape))\n",
    "\n",
    "            accuracy += torch.sum(equality)\n",
    "\n",
    "    overall_acc=accuracy.float()/images_num;\n",
    "    return test_loss,overall_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5..  Training Loss: 3.128..  Test Loss: 2.375..  Test Accuracy: 0.270\n",
      "Epoch: 2/5..  Training Loss: 2.325..  Test Loss: 1.796..  Test Accuracy: 0.445\n",
      "Epoch: 3/5..  Training Loss: 1.961..  Test Loss: 1.547..  Test Accuracy: 0.537\n",
      "Epoch: 4/5..  Training Loss: 1.750..  Test Loss: 1.370..  Test Accuracy: 0.575\n",
      "Epoch: 5/5..  Training Loss: 1.619..  Test Loss: 1.284..  Test Accuracy: 0.622\n"
     ]
    }
   ],
   "source": [
    "train_loss,test_loss,accuracy=train(Model,train_loader,valid_loader,criterion,optimizer,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5..  Training Loss: 1.534..  Test Loss: 1.186..  Test Accuracy: 0.652\n",
      "Epoch: 2/5..  Training Loss: 1.465..  Test Loss: 1.166..  Test Accuracy: 0.653\n",
      "Epoch: 3/5..  Training Loss: 1.404..  Test Loss: 1.155..  Test Accuracy: 0.656\n",
      "Epoch: 4/5..  Training Loss: 1.360..  Test Loss: 1.121..  Test Accuracy: 0.677\n",
      "Epoch: 5/5..  Training Loss: 1.326..  Test Loss: 1.086..  Test Accuracy: 0.691\n"
     ]
    }
   ],
   "source": [
    "train_loss,test_loss,accuracy=train(Model,train_loader,valid_loader,criterion,optimizer,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
